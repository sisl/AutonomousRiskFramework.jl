### A Pluto.jl notebook ###
# v0.12.16

using Markdown
using InteractiveUtils

# This Pluto notebook uses @bind for interactivity. When running this notebook outside of Pluto, the following 'mock version' of @bind gives bound variables a default value (instead of an error).
macro bind(def, element)
    quote
        local el = $(esc(element))
        global $(esc(def)) = Core.applicable(Base.get, el) ? Base.get(el) : missing
        el
    end
end

# â•”â•â•¡ e59459de-047d-11eb-3252-25dc1bac624c
try
	using Pkg
	using AddPackage
catch
	Pkg.add("AddPackage")
	using AddPackage
end

# â•”â•â•¡ 92ce9460-f62b-11ea-1a8c-179776b5a0b4
@add using Distributions, Parameters, Random, Latexify, PlutoUI

# â•”â•â•¡ e7783510-047d-11eb-26b0-373b14638ff0
try
	using POMDPStressTesting
catch
	pkg"add https://github.com/JuliaPOMDP/RLInterface.jl"
	pkg"dev https://github.com/sisl/POMDPStressTesting.jl"
	using POMDPStressTesting
end

# â•”â•â•¡ 687a90c0-0480-11eb-1ef4-03e93ffa400c
@add using AutomotiveSimulator, AutomotiveVisualization

# â•”â•â•¡ cda24800-0488-11eb-1d7f-8d52b5f6b33e
try
	using AdversarialDriving
catch
	pkg"dev https://github.com/sisl/AdversarialDriving.jl"
	using AdversarialDriving
end

# â•”â•â•¡ 3617eb60-0489-11eb-144a-232b222a0365
@add using POMDPs, POMDPPolicies, POMDPSimulators

# â•”â•â•¡ ae68e2e2-3bde-11eb-2133-41c25803770a
using STLCG

# â•”â•â•¡ e66d5b60-2614-11eb-0dba-9f6829ce2fe2
using Statistics

# â•”â•â•¡ 9061cd00-2b87-11eb-05e2-eb9b27484486
using PyPlot

# â•”â•â•¡ de0497b0-3be3-11eb-096c-99c1a584ca68
using CrossEntropyVariants

# â•”â•â•¡ 99e92652-3be7-11eb-0fb2-316c55af79a7
@add using DeepQLearning

# â•”â•â•¡ 7a71fe60-3be6-11eb-1fe7-7bd3ab22ffc9
using Flux

# â•”â•â•¡ 83e51830-f62a-11ea-215d-a9767d7b07a5
md"""
# Adaptive Stress Testing
Formulation of the autonomous vehicle risk problem using AST. The following code will automatically download any dependent packages (see the Pluto console output for debug information).
"""

# â•”â•â•¡ 9117e2d0-05c5-11eb-3d46-6d4be8e47477
Random.seed!(0); # reproducibility

# â•”â•â•¡ b7f29190-047e-11eb-28b1-559809f831f3
md"**Note**: *AST installation may take a few minutes the first time.*"

# â•”â•â•¡ 92a94b80-05b5-11eb-2f9c-871e36ad52ec
md"Notice we `dev` the `POMDPStressTesting` package, this puts the code in `~/.julia/dev`."

# â•”â•â•¡ 5d084480-0480-11eb-1329-c562528e965c
md"## Automotive Driving Problem"

# â•”â•â•¡ 2e62d8c0-048a-11eb-1822-4b40f0acd39b
md"""
### Adversarial Driver
This section provides the crosswalk example and visualizations to understand the problem AST is trying to solve. It involves an autonomous vehicle (i.e. ego vehicle) and a noisy pedestrian crossing a crosswalk.
"""

# â•”â•â•¡ 5f39b460-0489-11eb-2b4f-8168c3825150
# Base.rand(rng::AbstractRNG, s::Scene) = s

# â•”â•â•¡ a4a6b3e0-05b5-11eb-1a28-f528c5f88ee1
md"Again, notice we are `dev`-ing the `AdversarialDriving` package, in case we want to make changes."

# â•”â•â•¡ a9420670-04cf-11eb-33d4-89ba4afbe562
md"##### Agents"

# â•”â•â•¡ cefe6ab0-048a-11eb-0622-4b4e71cb0072
md"Define the system under test (SUT) agent."

# â•”â•â•¡ 2bd501f0-048a-11eb-3921-65a864fa990f
sut_agent = BlinkerVehicleAgent(get_ped_vehicle(id=1, s=5.0, v=15.0),
	                            TIDM(ped_TIDM_template, noisy_observations=true));

# â•”â•â•¡ ddd45450-048a-11eb-0561-e769f54a359c
md"Define the adversary, i.e. a noisy pedestrian"

# â•”â•â•¡ 55b0f332-048a-11eb-0733-5b98489ea1cc
adv_ped = NoisyPedestrianAgent(get_pedestrian(id=2, s=7.0, v=2.0),
	                           AdversarialPedestrian());

# â•”â•â•¡ b51a1960-04cf-11eb-169e-69fc0008aedc
md"##### Markov Decision Process"

# â•”â•â•¡ e7b02210-048a-11eb-33f6-010ce4d1e341
md"Instantiate the MDP structure, using the `ped_roadway` exported by `AdversarialDriving`."

# â•”â•â•¡ 5cc03370-048a-11eb-1d27-c71efabeffdd
ad_mdp = AdversarialDrivingMDP(sut_agent, [adv_ped], ped_roadway, 0.1);

# â•”â•â•¡ bfbba820-04cf-11eb-3879-31d8398c9545
md"##### Behaviors/Actions"

# â•”â•â•¡ 0a936850-048b-11eb-1fc8-13a204c0c7c0
md"Define the action that controls the pedestrian (no noise)."

# â•”â•â•¡ 601e79a0-048a-11eb-3c3e-d7d9fb813922
null_action = Disturbance[PedestrianControl()];

# â•”â•â•¡ 35d2ba20-048b-11eb-0f24-71380027dad4
md"Define the actions that controls a *noisy* pedestrian"

# â•”â•â•¡ 628f0470-048a-11eb-1a11-6bc32f2c3d1c
noisy_action = Disturbance[PedestrianControl(noise=Noise((-10.0, 0.0), -2))];

# â•”â•â•¡ 3cad38a0-05a5-11eb-3f6b-735eb1c3cb59
initialstate(ad_mdp)

# â•”â•â•¡ c6cc6f00-04cf-11eb-263c-c34c6a95db29
md"##### Simulation Histories"

# â•”â•â•¡ 4af33470-048b-11eb-0f8c-f93c7dcdb11b
md"Run a simulation for the nominal behavior (i.e. no noisy)."

# â•”â•â•¡ 6bd32610-048a-11eb-316d-6dd779f7cdc4
# Nominal Behavior
hist = POMDPSimulators.simulate(HistoryRecorder(), ad_mdp,
	                            FunctionPolicy((s) -> null_action));

# â•”â•â•¡ 573ec9b0-048b-11eb-3b97-17d0bbb8d28b
md"Run a simulation with the noisy pedestrian."

# â•”â•â•¡ 766dd700-048a-11eb-0faa-ed69d2203b0a
# Behavior with noise
hist_noise = POMDPSimulators.simulate(HistoryRecorder(), ad_mdp,
	                                  FunctionPolicy((s) -> noisy_action));

# â•”â•â•¡ d45ce322-0489-11eb-2b9d-71a00e65d8b0
# ad_scenes = state_hist(hist); # TODO: fix this bug???
ad_scenes = [s.s for s in hist];

# â•”â•â•¡ fb4732b0-0489-11eb-3e24-3d6ed2221771
# ad_scenes_noise = state_hist(hist_noise);
ad_scenes_noise = [s.s for s in hist_noise];

# â•”â•â•¡ 84985160-3be0-11eb-274f-9579e1337cc3
hist_noise

# â•”â•â•¡ 61b258b0-048d-11eb-0e0c-9d3f8c23b0ed
md"##### Distance Metrics"

# â•”â•â•¡ ab394dd0-3bde-11eb-266a-ade6c9ff5697
md"""
###### Distance using STL
"""

# â•”â•â•¡ b67e4880-3bde-11eb-185e-313a83ee528e
pkg"dev ../STLCG.jl/."

# â•”â•â•¡ b2869690-3be0-11eb-0199-8f72d717fe61
md"""
Notes:
- Use STL to define collision (i.e. is robustness zero or negative?)
- Use robustness as the distance metric.
"""

# â•”â•â•¡ e1090570-3be0-11eb-285d-8303a3401d8a
collisionâ‚›â‚œâ‚— = Always(subformula=GreaterThan(:d, 0), interval=nothing)

# â•”â•â•¡ 2d5e59b0-048d-11eb-257d-076254d3488f
function distance(ent1::Entity, ent2::Entity)
	pos1 = posg(ent1)
	pos2 = posg(ent2)
	d = hypot(pos1.x - pos2.x, pos1.y - pos2.y)
	return first(Ït(collisionâ‚›â‚œâ‚—, [d]')) # robustness (i.e. distance)
end

# â•”â•â•¡ 0626f970-3be1-11eb-101d-09cadd79b879
# function collision_stl(pos1, pos2)
	Ït(collisionâ‚›â‚œâ‚—, [10]')
# end

# â•”â•â•¡ 900269c0-0489-11eb-0031-c5f78fc2963a
@bind ad_t Slider(1:length(ad_scenes), default=12) # known failure at 12s

# â•”â•â•¡ 4c4b70c0-05a4-11eb-1530-5174e460580b
try
	nominal_vehicle, nominal_predestrian = ad_scenes[ad_t]
	distance(nominal_vehicle, nominal_predestrian)
catch
	NaN
end

# â•”â•â•¡ 73b27d00-0489-11eb-2db1-51b4c3966b8d
AutomotiveVisualization.render([ad_mdp.roadway, crosswalk, ad_scenes[ad_t]])

# â•”â•â•¡ f7f8cb00-0489-11eb-3758-c7ae4acaf16c
begin
	capped_t = min(ad_t, length(ad_scenes_noise))
	AutomotiveVisualization.render([ad_mdp.roadway, crosswalk,
			                        ad_scenes_noise[capped_t]])
end

# â•”â•â•¡ 7221b840-05a4-11eb-1982-2faa93fbd308
noisy_vehicle, noisy_pedestrian = ad_scenes_noise[capped_t];

# â•”â•â•¡ 9dd57770-048b-11eb-0078-8b3a21b9bc4a
distance(noisy_vehicle, noisy_pedestrian)

# â•”â•â•¡ 4d5e0420-05a2-11eb-19c5-8979d9423450
collision_checker(noisy_vehicle, noisy_pedestrian)

# â•”â•â•¡ 2978b840-f62d-11ea-2ea0-19d7857208b1
md"""
# Black-Box Stress Testing
"""

# â•”â•â•¡ 40d3b1e0-f630-11ea-2160-01338d9f2209
md"""
To find failures in a black-box autonomous system, we can use the `POMDPStressTesting` package which is part of the POMDPs.jl ecosystem.

Various solversâ€”which adhere to the POMDPs.jl interfaceâ€”can be used:
- `MCTSPWSolver` (MCTS with action progressive widening)
- `TRPOSolver` and `PPOSolver` (deep reinforcement learning policy optimization)
- `CEMSolver` (cross-entropy method)
- `RandomSearchSolver` (standard Monte Carlo random search)
"""

# â•”â•â•¡ 86f13f60-f62d-11ea-3241-f3f1ffe37d7a
md"""
## Working Problem: Pedestrian in a Crosswalk
We define a simple problem for adaptive stress testing (AST) to find failures. This problem, not colliding with a pedestrian in a crosswalk, samples random noise disturbances applied to the pedestrian's position and velocity from standard normal distributions $\mathcal{N}(\mu,\sigma)$. A failure is defined as a collision. AST will either select the seed which deterministically controls the sampled value from the distribution (i.e. from the transition model) or will directly sample the provided environmental distributions. These action modes are determined by the seed-action or sample-action options (`ASTSeedAction` and `ASTSampleAction`, respectively). AST will guide the simulation to failure events using a measure of distance to failure, while simultaneously trying to find the set of actions that maximizes the log-likelihood of the samples.
"""

# â•”â•â•¡ d3411dd0-f62e-11ea-27d7-1b2ed8edc415
md"""
## Gray-Box Simulator and Environment
The simulator and environment are treated as gray-box because we need access to the state-transition distributions and their associated likelihoods.
"""

# â•”â•â•¡ e37d7542-f62e-11ea-0b61-513a4b44fc3c
md"""
##### Parameters
First, we define the parameters of our simulation.
"""

# â•”â•â•¡ fd7fc880-f62e-11ea-15ac-f5407aeff2a6
@with_kw struct AutoRiskParams
	endtime::Real = 30 # Simulate end time
end;

# â•”â•â•¡ 012c2eb0-f62f-11ea-1637-c113ad01b144
md"""
##### Simulation
Next, we define a `GrayBox.Simulation` structure.
"""

# â•”â•â•¡ 0d7049de-f62f-11ea-3552-214fc4e7ec98
@with_kw mutable struct AutoRiskSim <: GrayBox.Simulation
    t::Real = 0 # Current time
    params::AutoRiskParams = AutoRiskParams() # Parameters

	# System under test, ego vehicle
	sut = BlinkerVehicleAgent(get_ped_vehicle(id=1, s=5.0, v=15.0),
                              TIDM(ped_TIDM_template, noisy_observations=true))

	# Noisy adversary, pedestrian
	adversary = NoisyPedestrianAgent(get_pedestrian(id=2, s=7.0, v=2.0),
	                                 AdversarialPedestrian())

	# Adversarial Markov decision process
	problem::MDP = AdversarialDrivingMDP(sut, [adversary], ped_roadway, 0.1)
	state::Scene = rand(initialstate(problem))
	prev_distance::Real = -Inf # Used when agent goes out of frame

	# Noise distributions and disturbances
	xposition_noise::Distribution = Normal(0, 5) # Gaussian noise (notice larger Ïƒ)
	yposition_noise::Distribution = Normal(0, 1) # Gaussian noise
	velocity_noise::Distribution = Normal(0, 1) # Gaussian noise
	disturbances = Disturbance[PedestrianControl()] # Initial 0-noise disturbance
end;

# â•”â•â•¡ 63326db0-05b9-11eb-0efe-ebd0e7cf3d17
md"**Note**: I avoid `MvNormal` (multivariate Gaussian) for the position noise, I'm submitting a change to the `CrossEntropyMethod` package that fixes this."

# â•”â•â•¡ 11e445d0-f62f-11ea-305c-495272981112
md"""
#### GrayBox.environment
Then, we define our `GrayBox.Environment` distributions. When using the `ASTSampleAction`, as opposed to `ASTSeedAction`, we need to provide access to the sampleable environment.
"""

# â•”â•â•¡ 43c8cb70-f62f-11ea-1b0d-bb04a4176730
function GrayBox.environment(sim::AutoRiskSim)
	return GrayBox.Environment(:xpos => sim.xposition_noise,
							   :ypos => sim.yposition_noise,
		                       :vel => sim.velocity_noise)
end

# â•”â•â•¡ 48a5e970-f62f-11ea-111d-35694f3994b4
md"""
#### GrayBox.transition!
We override the `transition!` function from the `GrayBox` interface, which takes an environment sample as input. We apply the sample in our simulator, take a step, and return the log-likelihood.
"""

# â•”â•â•¡ 5d0313c0-f62f-11ea-3d33-9ded1fb804e7
function GrayBox.transition!(sim::AutoRiskSim, sample::GrayBox.EnvironmentSample)
    sim.t += sim.problem.dt # Keep track of time

	# replace current noise with new sampled noise
	noise = Noise((sample[:xpos].value, sample[:ypos].value), sample[:vel].value)
	sim.disturbances[1] = PedestrianControl(noise=noise)

	# step agents: given MDP, current state, and current action (i.e. disturbances)
	(sim.state, r) = @gen(:sp, :r)(sim.problem, sim.state, sim.disturbances)

	# return log-likelihood of actions, summation handled by `logpdf()`
	return logpdf(sample)::Real
end

# â•”â•â•¡ 4d964d00-05b4-11eb-32d0-11df579faaa9
md"""
## Example
You can use this space to play around with the `GrayBox` and `BlackBox` interface functions.
"""

# â•”â•â•¡ d0c31180-05b0-11eb-159a-2702ed171fcf
simx = AutoRiskSim()

# â•”â•â•¡ 56f103e0-05b4-11eb-2de6-8f6daace22b6
md"**Example**: initializing the AST simulation object."

# â•”â•â•¡ ee99f6f0-05b1-11eb-186d-eb9039f0cfae
md"**Example**: sampling from the environment, applying a state transition, and calculating the distance."

# â•”â•â•¡ 965a6212-05b4-11eb-256a-63b6d10fb951
md"**Example**: or we could call `evaluate!` to do these step for us."

# â•”â•â•¡ 6e111310-f62f-11ea-33cf-b5e943b2f088
md"""
## Black-Box System
The system under test, in this case an autonomous vehicle with sensor noise, is treated as black-box. The following interface functions are overridden to minimally interact with the system, and use outputs from the system to determine failure event indications and distance metrics.
"""

# â•”â•â•¡ 7c84df7e-f62f-11ea-3b5f-8b090654df19
md"""
#### BlackBox.initialize!
Now we override the `BlackBox` interface, starting with the function that initializes the simulation object. Interface functions ending in `!` may modify the `sim` object in place.
"""

# â•”â•â•¡ 9b736bf2-f62f-11ea-0330-69ffafe9f200
function BlackBox.initialize!(sim::AutoRiskSim)
    sim.t = 0
    sim.problem = AdversarialDrivingMDP(sim.sut, [sim.adversary], ped_roadway, 0.1)
	sim.state = rand(initialstate(sim.problem))
	sim.disturbances = Disturbance[PedestrianControl()] # noise-less
	sim.prev_distance = -Inf
end

# â•”â•â•¡ 3df1c8c0-05b4-11eb-0407-89c259b45c10
BlackBox.initialize!(simx);

# â•”â•â•¡ 9d41f840-05c3-11eb-2395-0f4a9f68e3bc
out_of_frame(sim) = length(sim.state.entities) < 2 # either agent went out of frame

# â•”â•â•¡ a380e250-f62f-11ea-363d-2bf2b59d5eed
md"""
#### BlackBox.distance
We define how close we are to a failure event using a non-negative distance metric.
"""

# â•”â•â•¡ be39db60-f62f-11ea-3a5c-bd57114455ff
function BlackBox.distance(sim::AutoRiskSim)
	if out_of_frame(sim)
		return sim.prev_distance
	else
		pedestrian, vehicle = sim.state.entities
		return distance(pedestrian, vehicle)
	end
end

# â•”â•â•¡ adef6630-05b1-11eb-269f-a10c49a437ee
begin
	envsample = rand(GrayBox.environment(simx))
	GrayBox.transition!(simx, envsample)
	BlackBox.distance(simx)
end

# â•”â•â•¡ bf8917b0-f62f-11ea-0e77-b58065b0da3e
md"""
#### BlackBox.isevent
We indicate whether a failure event occurred, using `collision_checker` from `AutomotiveSimulator`.
"""

# â•”â•â•¡ c5f03110-f62f-11ea-1119-81f5c9ec9283
function BlackBox.isevent(sim::AutoRiskSim)
	if out_of_frame(sim)
		return false
	else
		pedestrian, vehicle = sim.state.entities
		return collision_checker(pedestrian, vehicle)
		# return BlackBox.distance(sim) <= 0
	end
end

# â•”â•â•¡ c378ef80-f62f-11ea-176d-e96e1be7736e
md"""
#### BlackBox.isterminal
Similarly, we define an indication that the simulation is in a terminal state.
"""

# â•”â•â•¡ cb5f7cf0-f62f-11ea-34ca-5f0656eddcd4
function BlackBox.isterminal(sim::AutoRiskSim)
    return isterminal(sim.problem, sim.state) ||
		   out_of_frame(sim) ||
		   BlackBox.isevent(sim) ||
	       sim.t â‰¥ sim.params.endtime
end

# â•”â•â•¡ e2f34130-f62f-11ea-220b-c7fc7de2c7e7
md"""
#### BlackBox.evaluate!
Lastly, we use our defined interface to evaluate the system under test. Using the input sample, we return the log-likelihood, distance to an event, and event indication.
"""

# â•”â•â•¡ 8f4abd70-2491-11eb-1044-0f3fdced32b9
md"""
## Rollouts
- **$$Q$$-rollout**: explore based on existing $$Q$$-values
- **$$\epsilon$$-greedy rollout**: take random action with probability $$\epsilon$$, best action otherwise
- **CEM-rollout**: use low-level CEM optimization approach to select rollout action
- Gaussian process-based $$Q$$-function approximation
- Neural network-based $$Q$$-function approximation
    -  $$Q(d,a)$$ encoding instead of $$Q(s,a)$$
"""

# â•”â•â•¡ a0660a70-2616-11eb-384b-f7998bf64235
# html"<style>ul li p {margin: 0} ol li p {margin: 0}</style>"# bulleted list spacing

# â•”â•â•¡ ce9b7d70-2b8a-11eb-08d1-93a7132feafe
global final_is_distrs = Any[nothing]

# â•”â•â•¡ f57a2ce0-2b8d-11eb-0abb-b71e527b3dad
final_is_distrs[1]

# â•”â•â•¡ f943e670-2b8a-11eb-0419-8f1987e9b052
# convert(Vector{GrayBox.Environment}, final_is_distrs, 29)

# â•”â•â•¡ 33dd9eb2-2b8c-11eb-3968-bf149aa4c850
# is_dist_0 = convert(Dict{Symbol, Vector{Sampleable}}, GrayBox.environment(ast_mdp.sim), 10)

# â•”â•â•¡ 515394e0-2b8c-11eb-0365-7384df7c294c
# samples = rand(Random.GLOBAL_RNG, is_dist_0, 10)

# â•”â•â•¡ 6668c490-2b8c-11eb-0e93-bf92bc74d37e
# losses_fn = (d, samples) -> [POMDPStressTesting.cem_losses(d, samples; mdp=ast_mdp, initstate=initialstate(ast_mdp))]

# â•”â•â•¡ a07ec352-2b8c-11eb-2196-3b7ecb053b74
# losses = losses_fn(is_dist_0, samples)

# â•”â•â•¡ 923e33e0-2491-11eb-1b9c-27f4842ad081
function cem_rollout(mdp::ASTMDP, s::ASTState, d::Int64)
	USE_PRIOR = false
	cem_mdp = mdp # deepcopy(mdp)
	prev_top_k = cem_mdp.params.top_k
	q_value = 0

	if USE_PRIOR # already computed importance sampling distribution
		is_distrs = final_is_distrs[1] # TODO: put this in `mdp`
	else
		cem_solver = CEMSolver(n_iterations=10,
							   num_samples=20,
							   episode_length=d,
							   show_progress=false)
		cem_mdp.params.top_k = 0
		cem_planner = solve(cem_solver, cem_mdp)
		is_distrs = convert(Vector{GrayBox.Environment}, search!(cem_planner, s), d)
		global final_is_distrs[1] = is_distrs
	end

	USE_MEAN = true # use the mean of the importance sampling distr, instead of rand.
	
	AST.go_to_state(mdp, s) # Records trace through this call

	for i in 1:length(is_distrs) # TODO: handle min(d, length) to select is_dist associated with `d`
		is_distr = is_distrs[1]
		if USE_MEAN
			sample = mean(is_distr)
		else
			sample = rand(is_distr)
		end
		# @info sample
		# @info is_distr
		a::ASTAction = ASTSampleAction(sample)
		# a::ASTAction = ASTSampleAction(rand(GrayBox.environment(mdp.sim)))
		# AST.random_action(mdp)
		(s, r) = @gen(:sp, :r)(cem_mdp, s, a, Random.GLOBAL_RNG)
		q_value = r + discount(cem_mdp)*q_value
		# AST.go_to_state(mdp, s) # Records trace through this call
	end
	# AST.go_to_state(mdp, s) # Records trace through this call
	cem_mdp.params.top_k = prev_top_k

	return q_value
end


# â•”â•â•¡ 91d48ec0-2614-11eb-30a6-33c89c9c07ef
D = Dict{Symbol,Distributions.Sampleable}(:vel => Distributions.Normal{Float64}(0.16191185557003204, 0.00010103246108517094),:xpos => Distributions.Normal{Float64}(-7.717689089890023, 5.7750315962668e-5),:ypos => Distributions.Normal{Float64}(0.8894044320100376, 3.3435841468310024e-6))

# â•”â•â•¡ bdef4c70-2614-11eb-1e70-51a2f4844295
function Statistics.mean(d::Dict)
	meand = Dict()
	for k in keys(d)
		m = mean(d[k])
		meand[k] = GrayBox.Sample(m, logpdf(d[k], m))
	end
	return meand
end

# â•”â•â•¡ b8875e20-2615-11eb-0f24-d700ce3fa5ab
logpdf(D[:vel], 0.16191185557003204)

# â•”â•â•¡ e2e4f7f0-2614-11eb-0221-2166dd21d555
rand(D)

# â•”â•â•¡ 1485bdce-2615-11eb-2551-0bcf8c4477fa
mean(D)

# â•”â•â•¡ dc2c8920-2536-11eb-1625-ab5ee68e2cce
md"""
**Ideas:**
- change CEM initial distribution (heavier)
- using the GP $$Q$$-values in the SELECTION process
"""

# â•”â•â•¡ 91ad8ed0-24a0-11eb-2518-450a0f95159f
@with_kw mutable struct BestAction
	a = nothing
	r = -Inf
end

# â•”â•â•¡ 01b0f140-24a1-11eb-2b51-c17654f8f698
global BEST_ACTION = BestAction()

# â•”â•â•¡ 61c885de-24a4-11eb-232e-5df113729f2d
BEST_ACTION

# â•”â•â•¡ dc2340f2-249f-11eb-0fab-b9545ba763f2
function record_best_action(mdp, a, r)
	global BEST_ACTION
	if r > BEST_ACTION.r # less than for distance `d`, greater than for reward `r`
		BEST_ACTION.a = a
		BEST_ACTION.r = r
	end
end

# â•”â•â•¡ 92e3e160-249f-11eb-0d10-c3c67a74428e
function Ïµ_rollout(mdp::ASTMDP, s::ASTState, d::Int64; Ïµ=0.5)
    if d == 0 || isterminal(mdp, s)
        AST.go_to_state(mdp, s) # Records trace through this call
        return 0.0
    else
		if rand() < Ïµ
			a::ASTAction = AST.random_action(mdp)
		else
			a = ASTSampleAction(BEST_ACTION.a)
		end

        (sp, r) = @gen(:sp, :r)(mdp, s, a, Random.GLOBAL_RNG)
        q_value = r + AST.discount(mdp)*Ïµ_rollout(mdp, sp, d-1; Ïµ=Ïµ)

        return q_value
    end
end


# â•”â•â•¡ fad2ab80-2b84-11eb-017a-6905ab6071b7
global ğ’Ÿ = Tuple{Tuple{Real,ASTAction}, Real}[]

# â•”â•â•¡ 3ffe0970-2b85-11eb-3fc2-cfd5d7ae02d7
ğ’Ÿ

# â•”â•â•¡ 9357b470-2b87-11eb-2477-cdc2d6db8846
begin
	x = [d for ((d,a), q) in ğ’Ÿ]
	y = [q for ((d,a), q) in ğ’Ÿ]
end

# â•”â•â•¡ bd6e16a0-2b87-11eb-0cba-b16b63f314ce
begin
	PyPlot.svg(false)
	clf()
	hist2D(x, y)
	xlabel(L"d")
	ylabel(L"Q")
	gcf()
end

# â•”â•â•¡ bdcba74e-2b84-11eb-07ac-c16716b887e9
function prior_rollout(mdp::ASTMDP, s::ASTState, d::Int64)
    if d == 0 || isterminal(mdp, s)
        AST.go_to_state(mdp, s) # Records trace through this call
        return 0.0
    else
		a::ASTAction = AST.random_action(mdp)
		distance = BlackBox.distance(mdp.sim)

        (sp, r) = @gen(:sp, :r)(mdp, s, a, Random.GLOBAL_RNG)
        q_value = r + AST.discount(mdp)*prior_rollout(mdp, sp, d-1)

		push!(ğ’Ÿ, ((distance, a), q_value))

        return q_value
    end
end


# â•”â•â•¡ 6784331e-249b-11eb-1c7c-85f91c2a0964
function AST.search!(planner::CEMPlanner, s::ASTState)
    mdp::ASTMDP = planner.mdp
    return action(planner, s)
end


# â•”â•â•¡ 6dab3da0-2498-11eb-1446-2fbf5c3fbb17
function Base.convert(::Type{Vector{GrayBox.Environment}}, distr::Dict{Symbol, Vector{Sampleable}}, max_steps::Integer=1)
    env_vector = GrayBox.Environment[]
	for t in 1:max_steps
		env = GrayBox.Environment()
		for k in keys(distr)
			env[k] = distr[k][t]
		end
		push!(env_vector, env)
	end
	return env_vector::Vector{GrayBox.Environment}
end

# â•”â•â•¡ c1b76a12-3be3-11eb-24f9-87990bc4141b
md"""
## Cross-Entropy Surrogate Method
"""

# â•”â•â•¡ c59df310-3be3-11eb-0e26-fb3a6fbb0c07
pkg"add https://github.com/mossr/CrossEntropyVariants.jl"

# â•”â•â•¡ cff128d0-3be5-11eb-01a3-65e012391e48
md"""
## Neural Network Q-Approximator
- Use distance $d$ as a _state proxy_
- Approximate $Q(d,a)$ using a neural network (DQN?)
- Collect data: $\mathcal{D} = (d, a) \to Q$
- Train network: input $d$ output action $a$ (DQN) or input $(d,a)$ output $Q$
"""

# â•”â•â•¡ 9579dac0-3be6-11eb-228d-c7a452e9914d
@with_kw mutable struct Args
	Î±::Float64 = 3e-4      # learning rate
	epochs::Int = 20       # number of epochs
	device::Function = cpu # gpu or cpu device
	throttle::Int = 1      # throttle print every X seconds
end

# â•”â•â•¡ 7beae2c0-3be6-11eb-0e3d-5ba4d0c3c354
model = Chain(Dense(1+6, 32), Dense(32, 1)) # d + |A| -> Q

# â•”â•â•¡ dc769d50-3be6-11eb-3478-453ba24f4e7d
ğ’Ÿ[1][1][2].sample

# â•”â•â•¡ 01da7aa0-f630-11ea-1262-f50453455766
md"""
## AST Setup and Running
Setting up our simulation, we instantiate our simulation object and pass that to the Markov decision proccess (MDP) object of the adaptive stress testing formulation. We use Monte Carlo tree search (MCTS) with progressive widening on the action space as our solver. Hyperparameters are passed to `MCTSPWSolver`, which is a simple wrapper around the POMDPs.jl implementation of MCTS. Lastly, we solve the MDP to produce a planner. Note we are using the `ASTSampleAction`.
"""

# â•”â•â•¡ fdf55130-f62f-11ea-33a4-a783b4d216dc
function setup_ast(seed=0)
    # Create gray-box simulation object
    sim::GrayBox.Simulation = AutoRiskSim()

    # AST MDP formulation object
    mdp::ASTMDP = ASTMDP{ASTSampleAction}(sim)
    mdp.params.debug = true # record metrics
    mdp.params.top_k = 10   # record top k best trajectories
    mdp.params.seed = seed  # set RNG seed for determinism

    # Hyperparameters for MCTS-PW as the solver
    solver = MCTSPWSolver(n_iterations=10,        # number of algorithm iterations
                          exploration_constant=1.0, # UCT exploration
                          k_action=1.0,             # action widening
                          alpha_action=0.95,         # action widening
                          depth=sim.params.endtime, # tree depth
						  # estimate_value=Ïµ_rollout) # rollout function
						  estimate_value=cem_rollout) # rollout function
						  # estimate_value=prior_rollout) # rollout function

    # Get online planner (no work done, yet)
    planner = solve(solver, mdp)

    return planner
end;

# â•”â•â•¡ 09c928f0-f631-11ea-3ef7-512a6bececcc
md"""
#### Searching for Failures
After setup, we search for failures using the planner and output the best action trace.
"""

# â•”â•â•¡ 17d0ed20-f631-11ea-2e28-3bb9ca9a445f
planner = setup_ast();

# â•”â•â•¡ 1c47f652-f631-11ea-15f6-1b9b59700f36
with_terminal() do
	global action_trace = search!(planner)
end

# â•”â•â•¡ 6ade4d00-05c2-11eb-3732-ff945f7ce127
md"""
### Figures
These plots show episodic-based metrics, miss distance, and log-likelihood distributions.
"""

# â•”â•â•¡ 8efa3720-05be-11eb-2c3e-9519eb7d8e7a
episodic_figures(planner.mdp); POMDPStressTesting.gcf()

# â•”â•â•¡ 22995300-05c2-11eb-3399-574d1fb2ed94
distribution_figures(planner.mdp); POMDPStressTesting.gcf()

# â•”â•â•¡ 21530220-f631-11ea-3994-319c862d51f9
md"""
#### Playback
We can also playback specific trajectories and print intermediate distance values.
"""

# â•”â•â•¡ 3b282ae0-f631-11ea-309d-639bf4411bb3
playback_trace = playback(planner, action_trace, BlackBox.distance, return_trace=true)

# â•”â•â•¡ 7473adb0-f631-11ea-1c87-0f76b18a9ab6
failure_rate = print_metrics(planner)

# â•”â•â•¡ 0d159de0-284f-11eb-230b-a1feaa0b0581
visualize(planner)

# â•”â•â•¡ b6244db0-f63a-11ea-3b48-89d427664f5e
md"""
### Other Solvers: Cross-Entropy Method
We can easily take our `ASTMDP` object (`planner.mdp`) and re-solve the MDP using a different solverâ€”in this case the `CEMSolver`.
"""

# â•”â•â•¡ c0cf83e0-05a5-11eb-32b5-6fb00cbc311b
ast_mdp = deepcopy(planner.mdp); # re-used from MCTS run.

# â•”â•â•¡ 17cd6400-3be8-11eb-30f5-8d31eadaa535
actions(ast_mdp) |> length

# â•”â•â•¡ 5043e8c0-284e-11eb-0c6d-7f3940b0a940
begin
	# TODO: get this index from the `trace` itself
	# findmax(ast_mdp.metrics.reward[ast_mdp.metrics.event])
	# findmax(ast_mdp.metrics.reward[ast_mdp.metrics.event])

	failure_likelihood_mcts =
		round(exp(maximum(planner.mdp.metrics.logprob[ast_mdp.metrics.event])), digits=4)

	Markdown.parse(string("\$\$p_\\text{likely} = ", failure_likelihood_mcts, "\$\$"))
end

# â•”â•â•¡ 824bdde0-05bd-11eb-0594-cddd54c49757
cem_solver = CEMSolver(n_iterations=100, episode_length=ast_mdp.sim.params.endtime)

# â•”â•â•¡ fb3fa610-f63a-11ea-2663-17224dc8aade
cem_planner = solve(cem_solver, ast_mdp);

# â•”â•â•¡ ac2ec420-24a2-11eb-3cd4-b3751126845c
md"Run CEM? $(@bind run_cem CheckBox())"

# â•”â•â•¡ 09c9e0b0-f63b-11ea-2d50-4154e3432fa0
with_terminal() do
	if run_cem
		global cem_action_trace = search!(cem_planner)
	end
end

# â•”â•â•¡ d4817b20-2493-11eb-2f0b-b18bd7f364e4
run_cem ? cem_action_trace : nothing

# â•”â•â•¡ 46b40e10-f63b-11ea-2375-1976bb637d51
md"Notice the failure rate is higher when using `CEMSolver` than `MCTSPWSolver`."

# â•”â•â•¡ de88b710-05c5-11eb-1795-a119590ad1c2
cem_failure_rate = print_metrics(cem_planner)

# â•”â•â•¡ 6b6fe810-24a2-11eb-2de0-5de07707e7c4
episodic_figures(cem_planner.mdp); POMDPStressTesting.gcf()

# â•”â•â•¡ 7412e7b0-24a2-11eb-0523-9bb85e449a80
distribution_figures(cem_planner.mdp); POMDPStressTesting.gcf()

# â•”â•â•¡ 38a4f220-2b89-11eb-14c6-c18aee509c28
md"""
## PPO solver
"""

# â•”â•â•¡ 3b4ae4d0-2b89-11eb-0176-b3b84ddc6ec3
ppo_solver = PPOSolver(num_episodes=100, episode_length=ast_mdp.sim.params.endtime)

# â•”â•â•¡ 6e7d2020-2b89-11eb-2153-236afd953dcd
ast_mdp_ppo = deepcopy(planner.mdp); # re-used from MCTS run.

# â•”â•â•¡ 69815690-2b89-11eb-3fbf-4b94773309da
ppo_planner = solve(ppo_solver, ast_mdp_ppo);

# â•”â•â•¡ e7a24060-2b8f-11eb-17ce-9751327ccc5a
md"Run PPO? $(@bind run_ppo CheckBox())"

# â•”â•â•¡ 8134b0c0-2b89-11eb-09f3-e50f52093132
with_terminal() do
	if run_ppo
		global ppo_action_trace = search!(ppo_planner)
	end
end

# â•”â•â•¡ a4fab5e2-2b89-11eb-1d20-b31c4761a77e
ppo_failure_rate = print_metrics(ppo_planner)

# â•”â•â•¡ 30b19e00-2b8a-11eb-1d25-91d098b53ac7
md"""
## Random baseline
"""

# â•”â•â•¡ fbff1c90-2b8f-11eb-1da5-91bb366a9f7e
md"Run random baseline? $(@bind run_rand CheckBox())"

# â•”â•â•¡ 371953a2-2b8a-11eb-3f00-9b04999863b7
if run_rand
	rand_solver = RandomSearchSolver(n_iterations=100,
		                             episode_length=ast_mdp.sim.params.endtime)
	ast_mdp_rand = deepcopy(planner.mdp) # re-used from MCTS run.
	# ast_mdp_rand.params.seed  = 0
	rand_planner = solve(rand_solver, ast_mdp_rand)
	rand_action_trace = search!(rand_planner)
	rand_failure_rate = print_metrics(rand_planner)
end

# â•”â•â•¡ 00dd9240-05c1-11eb-3d13-ff544dc94b5d
md"""
## Visualization of failure
We can visualize the failure with the highest likelihood found by AST.
"""

# â•”â•â•¡ 49bb9090-05c4-11eb-1aa9-8b4488a05654
begin
	# TODO: get this index from the `trace` itself
	# findmax(ast_mdp.metrics.reward[ast_mdp.metrics.event])
	# findmax(ast_mdp.metrics.reward[ast_mdp.metrics.event])

	failure_likelihood =
		round(exp(maximum(ast_mdp.metrics.logprob[ast_mdp.metrics.event])), digits=4)

	Markdown.parse(string("\$\$p = ", failure_likelihood, "\$\$"))
end

# â•”â•â•¡ 066f2bd0-05c4-11eb-032f-ad141ecd8070
roadway = cem_planner.mdp.sim.problem.roadway;

# â•”â•â•¡ 937c8392-05c1-11eb-0de5-191f4a5c2d8c
cem_trace = playback(cem_planner, cem_action_trace, sim->sim.state, return_trace=true)

# â•”â•â•¡ 25c274e0-05c1-11eb-3c1d-a591fde9722b
@bind fail_t Slider(1:length(cem_trace), default=length(cem_trace)) # ends in failure

# â•”â•â•¡ 06bf27ee-05c1-11eb-06ed-af4265dee892
AutomotiveVisualization.render([roadway, crosswalk, cem_trace[fail_t]])

# â•”â•â•¡ 801f8080-f631-11ea-0728-f15dddc3ef5d
md"""
## AST Reward Function
For reference, the AST reward function gives a reward of $0$ if an event is found, a reward of negative distance $d$ if no event is found at termination, and the log-likelihood $\log(p)$ during the simulation.
"""

# â•”â•â•¡ 8f06f650-f631-11ea-1c52-697060322173
# @latexify 
function R(p,e,d,Ï„)
    if Ï„ && e
        return 0
    elseif Ï„ && !e
        return -d
    else
        return log(p)
    end
end

# â•”â•â•¡ f6213a50-f62f-11ea-07c7-2dcc383c8042
function BlackBox.evaluate!(sim::AutoRiskSim, sample::GrayBox.EnvironmentSample)
    logprob::Real = GrayBox.transition!(sim, sample) # Step simulation
    d::Real       = BlackBox.distance(sim)           # Calculate miss distance
    event::Bool   = BlackBox.isevent(sim)            # Check event indication
    sim.prev_distance = d                            # Store previous distance
	r = R(exp(logprob), event, d, BlackBox.isterminal(sim))
	record_best_action(sim, sample, r)
	return (logprob::Real, d::Real, event::Bool)
end

# â•”â•â•¡ c6a61f40-05b4-11eb-1f1d-6950aaea7a8d
begin
	envsample2 = rand(GrayBox.environment(simx))
	BlackBox.evaluate!(simx, envsample2) # (log-likelihood, distance, isevent)
end

# â•”â•â•¡ Cell order:
# â•Ÿâ”€83e51830-f62a-11ea-215d-a9767d7b07a5
# â• â•e59459de-047d-11eb-3252-25dc1bac624c
# â• â•92ce9460-f62b-11ea-1a8c-179776b5a0b4
# â• â•9117e2d0-05c5-11eb-3d46-6d4be8e47477
# â•Ÿâ”€b7f29190-047e-11eb-28b1-559809f831f3
# â• â•e7783510-047d-11eb-26b0-373b14638ff0
# â•Ÿâ”€92a94b80-05b5-11eb-2f9c-871e36ad52ec
# â•Ÿâ”€5d084480-0480-11eb-1329-c562528e965c
# â• â•687a90c0-0480-11eb-1ef4-03e93ffa400c
# â•Ÿâ”€2e62d8c0-048a-11eb-1822-4b40f0acd39b
# â• â•cda24800-0488-11eb-1d7f-8d52b5f6b33e
# â• â•3617eb60-0489-11eb-144a-232b222a0365
# â• â•5f39b460-0489-11eb-2b4f-8168c3825150
# â•Ÿâ”€a4a6b3e0-05b5-11eb-1a28-f528c5f88ee1
# â•Ÿâ”€a9420670-04cf-11eb-33d4-89ba4afbe562
# â•Ÿâ”€cefe6ab0-048a-11eb-0622-4b4e71cb0072
# â• â•2bd501f0-048a-11eb-3921-65a864fa990f
# â•Ÿâ”€ddd45450-048a-11eb-0561-e769f54a359c
# â• â•55b0f332-048a-11eb-0733-5b98489ea1cc
# â•Ÿâ”€b51a1960-04cf-11eb-169e-69fc0008aedc
# â•Ÿâ”€e7b02210-048a-11eb-33f6-010ce4d1e341
# â• â•5cc03370-048a-11eb-1d27-c71efabeffdd
# â•Ÿâ”€bfbba820-04cf-11eb-3879-31d8398c9545
# â•Ÿâ”€0a936850-048b-11eb-1fc8-13a204c0c7c0
# â• â•601e79a0-048a-11eb-3c3e-d7d9fb813922
# â•Ÿâ”€35d2ba20-048b-11eb-0f24-71380027dad4
# â• â•628f0470-048a-11eb-1a11-6bc32f2c3d1c
# â• â•3cad38a0-05a5-11eb-3f6b-735eb1c3cb59
# â•Ÿâ”€c6cc6f00-04cf-11eb-263c-c34c6a95db29
# â•Ÿâ”€4af33470-048b-11eb-0f8c-f93c7dcdb11b
# â• â•6bd32610-048a-11eb-316d-6dd779f7cdc4
# â•Ÿâ”€573ec9b0-048b-11eb-3b97-17d0bbb8d28b
# â• â•766dd700-048a-11eb-0faa-ed69d2203b0a
# â• â•d45ce322-0489-11eb-2b9d-71a00e65d8b0
# â• â•fb4732b0-0489-11eb-3e24-3d6ed2221771
# â• â•84985160-3be0-11eb-274f-9579e1337cc3
# â•Ÿâ”€61b258b0-048d-11eb-0e0c-9d3f8c23b0ed
# â• â•2d5e59b0-048d-11eb-257d-076254d3488f
# â•Ÿâ”€ab394dd0-3bde-11eb-266a-ade6c9ff5697
# â• â•b67e4880-3bde-11eb-185e-313a83ee528e
# â• â•ae68e2e2-3bde-11eb-2133-41c25803770a
# â•Ÿâ”€b2869690-3be0-11eb-0199-8f72d717fe61
# â• â•e1090570-3be0-11eb-285d-8303a3401d8a
# â• â•0626f970-3be1-11eb-101d-09cadd79b879
# â• â•4c4b70c0-05a4-11eb-1530-5174e460580b
# â• â•7221b840-05a4-11eb-1982-2faa93fbd308
# â• â•9dd57770-048b-11eb-0078-8b3a21b9bc4a
# â• â•4d5e0420-05a2-11eb-19c5-8979d9423450
# â• â•900269c0-0489-11eb-0031-c5f78fc2963a
# â• â•73b27d00-0489-11eb-2db1-51b4c3966b8d
# â• â•f7f8cb00-0489-11eb-3758-c7ae4acaf16c
# â•Ÿâ”€2978b840-f62d-11ea-2ea0-19d7857208b1
# â•Ÿâ”€40d3b1e0-f630-11ea-2160-01338d9f2209
# â•Ÿâ”€86f13f60-f62d-11ea-3241-f3f1ffe37d7a
# â•Ÿâ”€d3411dd0-f62e-11ea-27d7-1b2ed8edc415
# â•Ÿâ”€e37d7542-f62e-11ea-0b61-513a4b44fc3c
# â• â•fd7fc880-f62e-11ea-15ac-f5407aeff2a6
# â•Ÿâ”€012c2eb0-f62f-11ea-1637-c113ad01b144
# â• â•0d7049de-f62f-11ea-3552-214fc4e7ec98
# â•Ÿâ”€63326db0-05b9-11eb-0efe-ebd0e7cf3d17
# â•Ÿâ”€11e445d0-f62f-11ea-305c-495272981112
# â• â•43c8cb70-f62f-11ea-1b0d-bb04a4176730
# â•Ÿâ”€48a5e970-f62f-11ea-111d-35694f3994b4
# â• â•5d0313c0-f62f-11ea-3d33-9ded1fb804e7
# â•Ÿâ”€4d964d00-05b4-11eb-32d0-11df579faaa9
# â• â•d0c31180-05b0-11eb-159a-2702ed171fcf
# â•Ÿâ”€56f103e0-05b4-11eb-2de6-8f6daace22b6
# â• â•3df1c8c0-05b4-11eb-0407-89c259b45c10
# â•Ÿâ”€ee99f6f0-05b1-11eb-186d-eb9039f0cfae
# â• â•adef6630-05b1-11eb-269f-a10c49a437ee
# â•Ÿâ”€965a6212-05b4-11eb-256a-63b6d10fb951
# â• â•c6a61f40-05b4-11eb-1f1d-6950aaea7a8d
# â•Ÿâ”€6e111310-f62f-11ea-33cf-b5e943b2f088
# â•Ÿâ”€7c84df7e-f62f-11ea-3b5f-8b090654df19
# â• â•9b736bf2-f62f-11ea-0330-69ffafe9f200
# â• â•9d41f840-05c3-11eb-2395-0f4a9f68e3bc
# â•Ÿâ”€a380e250-f62f-11ea-363d-2bf2b59d5eed
# â• â•be39db60-f62f-11ea-3a5c-bd57114455ff
# â•Ÿâ”€bf8917b0-f62f-11ea-0e77-b58065b0da3e
# â• â•c5f03110-f62f-11ea-1119-81f5c9ec9283
# â•Ÿâ”€c378ef80-f62f-11ea-176d-e96e1be7736e
# â• â•cb5f7cf0-f62f-11ea-34ca-5f0656eddcd4
# â•Ÿâ”€e2f34130-f62f-11ea-220b-c7fc7de2c7e7
# â• â•f6213a50-f62f-11ea-07c7-2dcc383c8042
# â•Ÿâ”€8f4abd70-2491-11eb-1044-0f3fdced32b9
# â• â•a0660a70-2616-11eb-384b-f7998bf64235
# â• â•ce9b7d70-2b8a-11eb-08d1-93a7132feafe
# â• â•f57a2ce0-2b8d-11eb-0abb-b71e527b3dad
# â• â•f943e670-2b8a-11eb-0419-8f1987e9b052
# â• â•33dd9eb2-2b8c-11eb-3968-bf149aa4c850
# â• â•515394e0-2b8c-11eb-0365-7384df7c294c
# â• â•6668c490-2b8c-11eb-0e93-bf92bc74d37e
# â• â•a07ec352-2b8c-11eb-2196-3b7ecb053b74
# â• â•923e33e0-2491-11eb-1b9c-27f4842ad081
# â• â•91d48ec0-2614-11eb-30a6-33c89c9c07ef
# â• â•e66d5b60-2614-11eb-0dba-9f6829ce2fe2
# â• â•bdef4c70-2614-11eb-1e70-51a2f4844295
# â• â•b8875e20-2615-11eb-0f24-d700ce3fa5ab
# â• â•e2e4f7f0-2614-11eb-0221-2166dd21d555
# â• â•1485bdce-2615-11eb-2551-0bcf8c4477fa
# â• â•dc2c8920-2536-11eb-1625-ab5ee68e2cce
# â• â•91ad8ed0-24a0-11eb-2518-450a0f95159f
# â• â•01b0f140-24a1-11eb-2b51-c17654f8f698
# â• â•61c885de-24a4-11eb-232e-5df113729f2d
# â• â•dc2340f2-249f-11eb-0fab-b9545ba763f2
# â• â•92e3e160-249f-11eb-0d10-c3c67a74428e
# â• â•fad2ab80-2b84-11eb-017a-6905ab6071b7
# â• â•3ffe0970-2b85-11eb-3fc2-cfd5d7ae02d7
# â• â•9061cd00-2b87-11eb-05e2-eb9b27484486
# â• â•9357b470-2b87-11eb-2477-cdc2d6db8846
# â• â•bd6e16a0-2b87-11eb-0cba-b16b63f314ce
# â• â•bdcba74e-2b84-11eb-07ac-c16716b887e9
# â• â•6784331e-249b-11eb-1c7c-85f91c2a0964
# â• â•6dab3da0-2498-11eb-1446-2fbf5c3fbb17
# â•Ÿâ”€c1b76a12-3be3-11eb-24f9-87990bc4141b
# â• â•c59df310-3be3-11eb-0e26-fb3a6fbb0c07
# â• â•de0497b0-3be3-11eb-096c-99c1a584ca68
# â•Ÿâ”€cff128d0-3be5-11eb-01a3-65e012391e48
# â• â•99e92652-3be7-11eb-0fb2-316c55af79a7
# â• â•7a71fe60-3be6-11eb-1fe7-7bd3ab22ffc9
# â• â•9579dac0-3be6-11eb-228d-c7a452e9914d
# â• â•7beae2c0-3be6-11eb-0e3d-5ba4d0c3c354
# â• â•17cd6400-3be8-11eb-30f5-8d31eadaa535
# â• â•dc769d50-3be6-11eb-3478-453ba24f4e7d
# â•Ÿâ”€01da7aa0-f630-11ea-1262-f50453455766
# â• â•fdf55130-f62f-11ea-33a4-a783b4d216dc
# â•Ÿâ”€09c928f0-f631-11ea-3ef7-512a6bececcc
# â• â•17d0ed20-f631-11ea-2e28-3bb9ca9a445f
# â• â•1c47f652-f631-11ea-15f6-1b9b59700f36
# â•Ÿâ”€6ade4d00-05c2-11eb-3732-ff945f7ce127
# â• â•8efa3720-05be-11eb-2c3e-9519eb7d8e7a
# â• â•22995300-05c2-11eb-3399-574d1fb2ed94
# â•Ÿâ”€21530220-f631-11ea-3994-319c862d51f9
# â• â•3b282ae0-f631-11ea-309d-639bf4411bb3
# â• â•7473adb0-f631-11ea-1c87-0f76b18a9ab6
# â•Ÿâ”€5043e8c0-284e-11eb-0c6d-7f3940b0a940
# â• â•0d159de0-284f-11eb-230b-a1feaa0b0581
# â•Ÿâ”€b6244db0-f63a-11ea-3b48-89d427664f5e
# â• â•c0cf83e0-05a5-11eb-32b5-6fb00cbc311b
# â• â•824bdde0-05bd-11eb-0594-cddd54c49757
# â• â•fb3fa610-f63a-11ea-2663-17224dc8aade
# â•Ÿâ”€ac2ec420-24a2-11eb-3cd4-b3751126845c
# â• â•09c9e0b0-f63b-11ea-2d50-4154e3432fa0
# â• â•d4817b20-2493-11eb-2f0b-b18bd7f364e4
# â•Ÿâ”€46b40e10-f63b-11ea-2375-1976bb637d51
# â• â•de88b710-05c5-11eb-1795-a119590ad1c2
# â• â•6b6fe810-24a2-11eb-2de0-5de07707e7c4
# â• â•7412e7b0-24a2-11eb-0523-9bb85e449a80
# â•Ÿâ”€38a4f220-2b89-11eb-14c6-c18aee509c28
# â• â•3b4ae4d0-2b89-11eb-0176-b3b84ddc6ec3
# â• â•6e7d2020-2b89-11eb-2153-236afd953dcd
# â• â•69815690-2b89-11eb-3fbf-4b94773309da
# â•Ÿâ”€e7a24060-2b8f-11eb-17ce-9751327ccc5a
# â• â•8134b0c0-2b89-11eb-09f3-e50f52093132
# â• â•a4fab5e2-2b89-11eb-1d20-b31c4761a77e
# â•Ÿâ”€30b19e00-2b8a-11eb-1d25-91d098b53ac7
# â•Ÿâ”€fbff1c90-2b8f-11eb-1da5-91bb366a9f7e
# â• â•371953a2-2b8a-11eb-3f00-9b04999863b7
# â•Ÿâ”€00dd9240-05c1-11eb-3d13-ff544dc94b5d
# â•Ÿâ”€49bb9090-05c4-11eb-1aa9-8b4488a05654
# â• â•066f2bd0-05c4-11eb-032f-ad141ecd8070
# â• â•937c8392-05c1-11eb-0de5-191f4a5c2d8c
# â• â•25c274e0-05c1-11eb-3c1d-a591fde9722b
# â• â•06bf27ee-05c1-11eb-06ed-af4265dee892
# â•Ÿâ”€801f8080-f631-11ea-0728-f15dddc3ef5d
# â• â•8f06f650-f631-11ea-1c52-697060322173
